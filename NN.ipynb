{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal Information\n",
    "- Name: **Fernando Martinez**\n",
    "- Student ID: **A19737173**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implement Neural Network from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings;   warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class Layer:\n",
    "    # Initialize weights. By default I used a normal distribution\n",
    "    def __init__(self, input_size, out_size, activation_func):\n",
    "        self.activation_func = activation_func\n",
    "        self.W = np.random.randn(out_size, input_size)\n",
    "        self.b = np.random.randn(self.W.shape[0],1)\n",
    "    # List of activation functions with their corresponding gradients\n",
    "    def activation_function(self, z): \n",
    "        if self.activation_func == 'relu':\n",
    "            result = np.maximum(0, z)\n",
    "            dresult = np.where(z <= 0, 0, 1)\n",
    "        if self.activation_func == 'tanh':\n",
    "            result = np.tanh(z)\n",
    "            dresult = 1 - result**2\n",
    "        if self.activation_func == 'softmax':\n",
    "            result = np.exp(z)/np.sum(np.exp(z),axis=0)\n",
    "            dresult = None\n",
    "        if self.activation_func == 'sigmoid':\n",
    "            result = 1/(1 + np.exp(-z))\n",
    "            dresult = result * (1 - result)\n",
    "        return result, dresult\n",
    "    # Forward propagation process in layer\n",
    "    def forward_propagation(self, input):\n",
    "        self.input = input\n",
    "        self.z = np.dot(self.W, np.transpose(self.input)) + self.b\n",
    "        self.a, _ = self.activation_function(self.z)\n",
    "        self.a = np.transpose(self.a)\n",
    "        return self.a\n",
    "    # Backward propagation process in layer\n",
    "    def backward_propagation(self, gradients_input, learning_rate):\n",
    "      self.gradients_input = gradients_input\n",
    "      if self.activation_func == 'softmax':\n",
    "          self.dw = np.dot(self.gradients_input.T, self.input)\n",
    "          self.db = np.sum(self.gradients_input, axis=0).reshape(-1,1)\n",
    "          gradients_output = np.dot(self.gradients_input, self.W)\n",
    "      else:\n",
    "          _, self.dz = self.activation_function(self.z)\n",
    "          self.dz = np.transpose(self.gradients_input) * self.dz\n",
    "          self.dw = np.dot(self.dz, self.input)\n",
    "          self.db = np.sum(self.dz, axis=1).reshape(-1,1)\n",
    "          gradients_output = np.dot(np.transpose(self.dz), self.W)\n",
    "      self.W -= learning_rate * self.dw\n",
    "      self.b -= learning_rate * self.db\n",
    "      return gradients_output\n",
    "        \n",
    "class NN:\n",
    "    def __init__(self, architecture, loss_type='CrossEntropy', metric='Accuracy',learning_rate_pool=[0.001,0.002,0.0015]):\n",
    "        self.architecture = architecture # NN architecture to use\n",
    "        self.loss_type = loss_type # Type of loss function\n",
    "        self.learning_rate = np.random.choice(learning_rate_pool) # random sampling across list of different learning rates\n",
    "        self.metric = metric # By default accuracy\n",
    "        self.loss_log = []; self.metric_log = [] # Store loss and metric results\n",
    "\n",
    "    # To make predictions we will run forward prop\n",
    "    def predict(self, input):\n",
    "        output = input\n",
    "        for layer in self.architecture:\n",
    "            output = layer.forward_propagation(output)\n",
    "        return output\n",
    "    # Training process\n",
    "    def train(self, X_train, y_train, epochs, batch_size):\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"Epoch: {epoch}...\")\n",
    "            \n",
    "            for i in range(0,X_train.shape[0],batch_size):\n",
    "                data, target = X_train[i:i+batch_size],y_train[i:i+batch_size]\n",
    "                # forward propagation\n",
    "                output = self.predict(data)\n",
    "                # error\n",
    "                _, gradient = self.loss(y=target, yhat=output)\n",
    "\n",
    "                #backpropagation\n",
    "                for Layer in reversed(self.architecture):\n",
    "                    gradient = Layer.backward_propagation(gradient, self.learning_rate)\n",
    "\n",
    "            loss = self.loss(y_train, self.predict(X_train))[0]\n",
    "            self.loss_log.append(loss)\n",
    "            metric_result = self.accuracy(X_train, y_train)\n",
    "            self.metric_log.append(metric_result)\n",
    "            print(f\"Train {self.metric}: {metric_result}\")\n",
    "\n",
    "    # Loss function\n",
    "    def loss(self, y, yhat):\n",
    "        # Multiclass problems \n",
    "        if self.loss_type == 'CrossEntropy':\n",
    "            CrossEntropy = -np.sum(y * np.log(yhat), axis=1)\n",
    "            gradient =  (yhat - y)/len(yhat)\n",
    "            total_CrossEntropy = np.mean(CrossEntropy)\n",
    "        # For Binary problems (0 or 1) \n",
    "        if self.loss_type == 'BinaryCrossEntropy':\n",
    "            CrossEntropy = np.sum(-np.expand_dims(y, axis=1)*np.log(yhat) - (1-np.expand_dims(y, axis=1))*np.log(1-yhat))\n",
    "            gradient =  (-np.expand_dims(y, axis=1)/yhat + (1-np.expand_dims(y, axis=1))/(1-yhat))/len(yhat)\n",
    "            total_CrossEntropy = np.mean(CrossEntropy)\n",
    "        return total_CrossEntropy, gradient\n",
    "    # Accuracy metric by hand    \n",
    "    def accuracy(self, X, y):\n",
    "        return np.mean(np.round(self.predict(X)) == np.round(np.expand_dims(y, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0...\n",
      "Train Accuracy: 0.6125\n",
      "Epoch: 1...\n",
      "Train Accuracy: 0.7125\n",
      "Epoch: 2...\n",
      "Train Accuracy: 0.7375\n",
      "Epoch: 3...\n",
      "Train Accuracy: 0.75\n",
      "Epoch: 4...\n",
      "Train Accuracy: 0.7875\n",
      "Epoch: 5...\n",
      "Train Accuracy: 0.8\n",
      "Epoch: 6...\n",
      "Train Accuracy: 0.825\n",
      "Epoch: 7...\n",
      "Train Accuracy: 0.8375\n",
      "Epoch: 8...\n",
      "Train Accuracy: 0.8625\n",
      "Epoch: 9...\n",
      "Train Accuracy: 0.8625\n",
      "Epoch: 10...\n",
      "Train Accuracy: 0.8875\n",
      "Epoch: 11...\n",
      "Train Accuracy: 0.8875\n",
      "Epoch: 12...\n",
      "Train Accuracy: 0.9\n",
      "Epoch: 13...\n",
      "Train Accuracy: 0.9\n",
      "Epoch: 14...\n",
      "Train Accuracy: 0.9\n",
      "Epoch: 15...\n",
      "Train Accuracy: 0.9125\n",
      "Epoch: 16...\n",
      "Train Accuracy: 0.9125\n",
      "Epoch: 17...\n",
      "Train Accuracy: 0.9125\n",
      "Epoch: 18...\n",
      "Train Accuracy: 0.9125\n",
      "Epoch: 19...\n",
      "Train Accuracy: 0.9125\n",
      "Epoch: 20...\n",
      "Train Accuracy: 0.925\n",
      "Epoch: 21...\n",
      "Train Accuracy: 0.925\n",
      "Epoch: 22...\n",
      "Train Accuracy: 0.925\n",
      "Epoch: 23...\n",
      "Train Accuracy: 0.925\n",
      "Epoch: 24...\n",
      "Train Accuracy: 0.925\n",
      "Epoch: 25...\n",
      "Train Accuracy: 0.925\n",
      "Epoch: 26...\n",
      "Train Accuracy: 0.925\n",
      "Epoch: 27...\n",
      "Train Accuracy: 0.9375\n",
      "Epoch: 28...\n",
      "Train Accuracy: 0.9375\n",
      "Epoch: 29...\n",
      "Train Accuracy: 0.95\n",
      "Epoch: 30...\n",
      "Train Accuracy: 0.95\n",
      "Epoch: 31...\n",
      "Train Accuracy: 0.95\n",
      "Epoch: 32...\n",
      "Train Accuracy: 0.95\n",
      "Epoch: 33...\n",
      "Train Accuracy: 0.95\n",
      "Epoch: 34...\n",
      "Train Accuracy: 0.95\n",
      "Epoch: 35...\n",
      "Train Accuracy: 0.95\n",
      "Epoch: 36...\n",
      "Train Accuracy: 0.95\n",
      "Epoch: 37...\n",
      "Train Accuracy: 0.9625\n",
      "Epoch: 38...\n",
      "Train Accuracy: 0.9625\n",
      "Epoch: 39...\n",
      "Train Accuracy: 0.9625\n",
      "Epoch: 40...\n",
      "Train Accuracy: 0.9625\n",
      "Epoch: 41...\n",
      "Train Accuracy: 0.9625\n",
      "Epoch: 42...\n",
      "Train Accuracy: 0.9625\n",
      "Epoch: 43...\n",
      "Train Accuracy: 0.9625\n",
      "Epoch: 44...\n",
      "Train Accuracy: 0.9625\n",
      "Epoch: 45...\n",
      "Train Accuracy: 0.9625\n",
      "Epoch: 46...\n",
      "Train Accuracy: 0.9625\n",
      "Epoch: 47...\n",
      "Train Accuracy: 0.9625\n",
      "Epoch: 48...\n",
      "Train Accuracy: 0.9625\n",
      "Epoch: 49...\n",
      "Train Accuracy: 0.9625\n"
     ]
    }
   ],
   "source": [
    "# Standard Scaler made from scratch\n",
    "class StandardScaler:\n",
    "    # Standard Scaler\n",
    "    def fit(self, X):\n",
    "        self.sample_mean = np.mean(X, axis=0).values\n",
    "        self.sample_std = np.std(X, axis=0).values\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        self.sample_mean = np.mean(X, axis=0).values\n",
    "        self.sample_std = np.std(X, axis=0).values\n",
    "        return np.array((X - self.sample_mean)/self.sample_std)\n",
    "\n",
    "data_path = \"data.csv\"\n",
    "data = pd.read_csv(data_path, header=None)\n",
    "X = data.iloc[:,0:2]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "scaler_HandCrafted = StandardScaler()\n",
    "X_scaled = scaler_HandCrafted.fit_transform(X)\n",
    "X_train, x_validation, y_train, y_validation = train_test_split(X_scaled, y,test_size = 0.2)\n",
    "\n",
    "# # training neural network\n",
    "nn = NN(architecture=[Layer(2, 64, activation_func='relu'), \n",
    "                      Layer(64, 1, activation_func='sigmoid')], \n",
    "        loss_type=\"BinaryCrossEntropy\")\n",
    "nn.train(X_train, y_train, epochs=50, batch_size=1) #Stochastic Gradient descent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My implementation's accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on test/validation data\n",
    "print(f\"My implementation's accuracy: {nn.accuracy(x_validation, y_validation)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. TensorFlow/Keras Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7411 - accuracy: 0.4375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-10 18:09:46.707944: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 99ms/step - loss: 0.7451 - accuracy: 0.4375 - val_loss: 0.7051 - val_accuracy: 0.5500\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.7377 - accuracy: 0.4625 - val_loss: 0.7003 - val_accuracy: 0.5500\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.7306 - accuracy: 0.4750 - val_loss: 0.6952 - val_accuracy: 0.6000\n",
      "Epoch 4/50\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7123 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-10 18:09:46.963355: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 19ms/step - loss: 0.7232 - accuracy: 0.5000 - val_loss: 0.6908 - val_accuracy: 0.6500\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.7164 - accuracy: 0.5625 - val_loss: 0.6863 - val_accuracy: 0.6500\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.7097 - accuracy: 0.5625 - val_loss: 0.6819 - val_accuracy: 0.6500\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.7031 - accuracy: 0.5625 - val_loss: 0.6776 - val_accuracy: 0.6500\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6972 - accuracy: 0.6000 - val_loss: 0.6732 - val_accuracy: 0.6500\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6912 - accuracy: 0.6250 - val_loss: 0.6693 - val_accuracy: 0.6500\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6858 - accuracy: 0.6250 - val_loss: 0.6656 - val_accuracy: 0.6500\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6796 - accuracy: 0.6250 - val_loss: 0.6617 - val_accuracy: 0.6500\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6742 - accuracy: 0.6500 - val_loss: 0.6579 - val_accuracy: 0.7500\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6687 - accuracy: 0.6500 - val_loss: 0.6541 - val_accuracy: 0.7500\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6632 - accuracy: 0.6750 - val_loss: 0.6501 - val_accuracy: 0.7500\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6577 - accuracy: 0.6750 - val_loss: 0.6464 - val_accuracy: 0.7500\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6525 - accuracy: 0.6750 - val_loss: 0.6429 - val_accuracy: 0.8000\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6473 - accuracy: 0.7000 - val_loss: 0.6393 - val_accuracy: 0.8500\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6427 - accuracy: 0.7375 - val_loss: 0.6358 - val_accuracy: 0.8500\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6379 - accuracy: 0.7500 - val_loss: 0.6323 - val_accuracy: 0.8500\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6332 - accuracy: 0.7875 - val_loss: 0.6286 - val_accuracy: 0.8500\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6286 - accuracy: 0.8000 - val_loss: 0.6254 - val_accuracy: 0.8500\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6241 - accuracy: 0.8000 - val_loss: 0.6221 - val_accuracy: 0.8500\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6195 - accuracy: 0.8125 - val_loss: 0.6192 - val_accuracy: 0.8500\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6148 - accuracy: 0.8125 - val_loss: 0.6160 - val_accuracy: 0.8500\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6105 - accuracy: 0.8125 - val_loss: 0.6130 - val_accuracy: 0.8500\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6061 - accuracy: 0.8375 - val_loss: 0.6100 - val_accuracy: 0.8500\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6019 - accuracy: 0.8375 - val_loss: 0.6068 - val_accuracy: 0.8500\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5977 - accuracy: 0.8500 - val_loss: 0.6038 - val_accuracy: 0.8500\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5934 - accuracy: 0.8500 - val_loss: 0.6009 - val_accuracy: 0.8500\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5893 - accuracy: 0.8750 - val_loss: 0.5980 - val_accuracy: 0.9000\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5856 - accuracy: 0.8750 - val_loss: 0.5953 - val_accuracy: 0.9000\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5817 - accuracy: 0.8750 - val_loss: 0.5925 - val_accuracy: 0.9000\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5780 - accuracy: 0.8750 - val_loss: 0.5897 - val_accuracy: 0.9000\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5745 - accuracy: 0.8750 - val_loss: 0.5868 - val_accuracy: 0.9000\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5709 - accuracy: 0.8750 - val_loss: 0.5843 - val_accuracy: 0.9000\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5672 - accuracy: 0.8875 - val_loss: 0.5818 - val_accuracy: 0.9000\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5634 - accuracy: 0.9000 - val_loss: 0.5793 - val_accuracy: 0.9000\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5597 - accuracy: 0.9000 - val_loss: 0.5765 - val_accuracy: 0.9000\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5564 - accuracy: 0.9000 - val_loss: 0.5740 - val_accuracy: 0.9000\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5528 - accuracy: 0.9000 - val_loss: 0.5712 - val_accuracy: 0.9000\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5494 - accuracy: 0.9000 - val_loss: 0.5686 - val_accuracy: 0.9000\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5460 - accuracy: 0.9000 - val_loss: 0.5659 - val_accuracy: 0.9000\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5429 - accuracy: 0.9000 - val_loss: 0.5634 - val_accuracy: 0.9000\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5397 - accuracy: 0.9000 - val_loss: 0.5607 - val_accuracy: 0.9000\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5364 - accuracy: 0.9000 - val_loss: 0.5584 - val_accuracy: 0.9000\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5332 - accuracy: 0.9125 - val_loss: 0.5557 - val_accuracy: 0.9000\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5301 - accuracy: 0.9250 - val_loss: 0.5532 - val_accuracy: 0.9000\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5268 - accuracy: 0.9250 - val_loss: 0.5509 - val_accuracy: 0.9000\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5238 - accuracy: 0.9250 - val_loss: 0.5484 - val_accuracy: 0.9000\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5207 - accuracy: 0.9250 - val_loss: 0.5462 - val_accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model_tf = tf.keras.Sequential([tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "                            tf.keras.layers.Dense(1, activation=\"sigmoid\")])\n",
    "model_tf.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.SGD(),\n",
    "                metrics=[\"accuracy\"])\n",
    "history = model_tf.fit(X_train, np.squeeze(y_train), epochs=50, validation_data=(x_validation, np.squeeze(y_validation)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5462 - accuracy: 0.9000\n",
      "TensorFlow accuracy: 0.9000000357627869\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "print(f\"TensorFlow accuracy: {model_tf.evaluate(x_validation, y_validation)[1]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**:\n",
    "\n",
    "Both models, the architecture made from scratch and the one from the Tensorflow/Keras implementation, with the same configuration, achieve the same validation performance, resulting in 90% accuracy. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tensorflow-metal')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d17a86051e4127b87e7c760ce4d423064a89cbc689e5454215ad7e06419f5735"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
